#!/usr/bin/env python
#
# Utility functions for working with fault dictionaries in python.
# Written by Matthew Beckler - mbeckler at cmu dot edu
# Last updated: March 22, 2011

import re, sys, os, copy, math
import operator

def pretty_time(s):
    if s == float("inf"):
        return "(inf)"
    else:
        m, s = divmod(s, 60)
        h, m = divmod(m, 60)
        if (h > 24):
            d, h = divmod(h, 24)
            return "%dd %d:%02d:%02d" % (d, h, m, s)
        else:
            return "%d:%02d:%02d" % (h, m, s)

def estimated_time_left(time_so_far, progress):
    """ This function estimates the remaining time for your process based on the amount of work completed (between 0 and 1) and the time it's taken so far (in seconds). Returns an interger number of seconds. """
    if progress > 0:
        return int( ((1 - progress) * time_so_far) / progress )
    else:
        return float("inf")

def print_bins(values, width=0, zero_pad=True, prefix=""):
    """ Prints a series of numbers in equal-width binary fashion, based on either the specified width or the width of the maximum width value. If you specify prefix it will be printed before each line (nice for indenting a block of values to display. """
    max_width = 0
    for v in values:
        max_width = max(len(b(v, width, zero_pad)), max_width)
    for v in values:
        print prefix + b(v, max_width, zero_pad)


def b(x, width=0, zero_pad=True):
    """ Convert to binary with no '0b' prefix and pads it with zeros if zero_pad == True (otherwise pads with left-most bit like for sign extension) on the left to width. If width < len(bin(x)[2:]) then width is ignored and no padding is added."""
    start = bin(x)[2:]
    pad_char = "0" if zero_pad else start[0]
    return pad_char*(width - len(start)) + start

def chunks(sequence, num):
    """ Divides sequence into num chunks. Each chunk will not be a subsequence, but that usually doesn't matter. This is useful for dividing a list of work_ids amongst num threads. From http://code.activestate.com/recipes/425397-split-a-list-into-roughly-equal-sized-pieces/#c6 """
    return [sequence[i::num] for i in range(num)]

# ------------------------------------------------------------------------------

def plot_histogram(data, basename="histogram"):
    """ Plots the data provided as a histogram, saves it as an SVG, and then converts it to a PNG file."""
    import matplotlib
    import matplotlib.pyplot as plt
    import matplotlib.patches
    import subprocess

    width = 0.5

    indices = data.keys()
    fig = plt.figure()
    ax1 = fig.add_subplot(111)
    ax1.set_ylabel("Count")
    rects1 = ax1.bar(indices, data.values(), width)

    plt.savefig(basename + ".svg", transparent=True)
    subprocess.call(["inkscape", "-z", "-e", basename + ".png", "-D", "-f", basename + ".svg", "-w", "2000", "-y", "1"])

# ------------------------------------------------------------------------------
def read_simple_config(filename):
    """ Reads in a file with simple "key = value" lines, strips spaces from both ends of both key and value, and returns a dictionary. If the specified file does not exist, returns an empty dictionary."""
    config = {}
    if os.path.exists(filename):
        for line in file(filename):
            line = line.strip()
            if not line.startswith("#"):
                key, value = [kv.strip() for kv in line.split("=", 1)]
                config[key] = value
    # else: just return the blank dictionary
    return config

def write_simple_config(filename, dict):
    """ Creates a file with simple "key = value" lines, usings k:v pairs from a dictionary. """
    with open(filename, "w") as fid:
        for k, v in dict.iteritems():
            fid.write("%s = %s\n" % (str(k), str(v)))


def read_trees_dict(filename):
    """ Reads in a file where each line is a dictionary. Returns this list. """
    trees = []
    for tree in file(filename):
        tree = tree.strip()
        trees.append(eval(tree))
    return trees

def write_trees_dict(filename, trees):
    """ Creates a file with each line of the trees list saved in plain text. """
    with open(filename, "w") as fid:
        for tree in trees:
            fid.write(str(tree) + "\n")


# ------------------------------------------------------------------------------
# Functions to parse the output files from tetramax, an ATPG and fault simulator

def parse_tmax_faults(filename):
    """ Returns a list of (net, fault) tuples. """
    faults = []
    for line in file(filename):
        fault, junk, net = line.split()
        faults.append( (net, fault) )
    return faults

# this function parses a verilog test file for transition fault test pairs, generated by tmax
def parse_tmax_tests_tf_verilog(filename):
    """ Returns a list of (PI_V1, PI_V2, PO) tuples, one for each test vector pair, and a list of the net names of the POs """
    tests = []
    po_list = []
    temp_v1 = None
    temp_v2 = None
    temp_po = None
    in_pi = False
    in_allpis = False
    in_xpct = False
    for line in file(filename):
        line = line.strip()
        if line.startswith("//"):
            continue
        if line.startswith("POnames"):
            a, equals, net = line.split()
            id = a[a.find('[')+1:-1]
            net = net.strip(";").strip("\"")
            po_list.append(net)

        if in_pi:
            temp = line.split("'")[1]
            if "}" in temp: # last one
                temp_v1 += temp[1:-2]
                in_pi = False
            else:
                temp_v1 += temp[1:-1]
        if in_allpis:
            temp = line.split("'")[1]
            if "}" in temp: # last one
                temp_v2 += temp[1:-2]
                in_allpis = False
            else:
                temp_v2 += temp[1:-1]
        if in_xpct:
            temp = line.split("'")[1]
            if "}" in temp: # last one
                temp_po += temp[1:-2]
                in_xpct = False
                tests.append( (temp_v1, temp_v2, temp_po) )
            else:
                temp_po += temp[1:-1]
        if line.startswith("#0 PI"):
            if ";" not in line: # this is a multi-line file, ugh
                in_pi = True
            temp_v1 = line.split("'")[1][1:-1]
        if line.startswith("ALLPIS"):
            if ";" not in line: # this is a multi-line file, ugh
                in_allpis = True
            temp_v2 = line.split("'")[1][1:-1]
        if line.startswith("XPCT"):
            temp_po = line.split("'")[1][1:-1]
            if ";" not in line: # this is a multi-line file, ugh
                in_xpct = True
            else:
                tests.append( (temp_v1, temp_v2, temp_po) )

    return tests, po_list

 
# this function parses a verilog test file output from tmax
# It probably works just fine for SSL faults (TODO check this), but for transition faults it's definitely wrong.
# It just looks at the expected response (fine) and the ALLPIS inputs (which is just V2 of the V1->V2 transition fault test pair, which is only half of what we need)
# If you're doing transition fault test pairs, used parse_tmax_tests_tf_verilog() instead!
def parse_tmax_tests(filename):
    """ Returns a list of (PIs, POs) tuples, one for each test, and a list of the net names of the POs """
    tests = []
    po_list = []
    temp_pis = None
    for line in file(filename):
        line = line.strip()
        if line.startswith("//"):
            continue
        if line.startswith("POnames"):
            a, equals, net = line.split()
            id = a[a.find('[')+1:-1]
            net = net.strip(";").strip("\"")
            po_list.append(net)
        if line.startswith("ALLPIS"):
            temp_pis = line.split("'")[1][1:-1]
        if line.startswith("XPCT"):
            if temp_pis == None:
                print "Error! temp_pis should never be None"
                sys.exit(1)
            tests.append( (temp_pis, line.split("'")[1][1:-1]) )

    return tests, po_list

def parse_tmax_sim_result(filename, po_list, fault_data):
    """ Used to parse a sim file containing results for all tests under a single stuck at fault. Example line:
    0  N223  (exp=0, got=1)
    That would be test 0, PO N223, expected value was 0, actually got a 1.
    Returns: a list of the complete response of the circuit to each test:
        ['101010101', '101010010', ...] """
    my_fault_data = copy.deepcopy(fault_data)

    for line in file(filename):
        if ".pattern_file_name" not in line:
            test_id, net, junk_0, junk_1 = line.split()
            test_id = int(test_id)
            po_id = po_list.index(net)
            #print "------------------------------------"
            #print "    net:", net
            #print "    test_id:", test_id
            #print "    po_id:", po_id, 
            #print ""
            #print "    my_fault_data is (%d, %d)" % (len(my_fault_data), len(my_fault_data[0]))
            # invert the value, since each line indicates an output bit that is incorrect
            if (my_fault_data[test_id][po_id] == '1'):
                my_fault_data[test_id][po_id] = '0'
            else:
                my_fault_data[test_id][po_id] = '1'


    return [''.join(test) for test in my_fault_data]




def pin_to_file_name(node):
    return re.sub('/', '_', node)


# ------------------------------------------------------------------------------
# Functions to write different kinds of fault dictionary to disk

def write_full(filename, dict_by_fault_full):
    fid = open(filename, "w")
    for fault in dict_by_fault_full:
        fid.write(" ".join(fault) + "\n")
    fid.close()

def write_pass_fail(filename, dict_by_fault_pass_fail):
    fid = open(filename, "w")
    for fault in dict_by_fault_pass_fail:
        fid.write(" ".join(fault) + "\n")
    fid.close()

def write_xored_pass_fail(filename, dict_by_fault_xored_pass_fail):
    fid = open(filename, "w")
    for fault in dict_by_fault_xored_pass_fail:
        fid.write(" ".join(fault) + "\n")
    fid.close()

def write_compact(filename, dict_by_fault_compact):
    fid = open(filename, "w")
    fid.write("TODO - write_compact is not finished yet - go bug Matthew (mbeckler at cmu dot edu) or do it yourself")
    #fid.write("\n".join([str(test) for test in compact_by_test]) + "\n")
    fid.close()

# ------------------------------------------------------------------------------
# Functions to evaluate different kinds of fault dictionary

def eval_full(dict_by_fault_full):
    signatures = {}
    fault_id = 0
    num_faults = len(dict_by_fault_full)
    num_tests = len(dict_by_fault_full[0])
    num_po = len(dict_by_fault_full[0][0])
    num_bits = num_faults * num_tests * num_po
    for fault in dict_by_fault_full:
        signatures.setdefault(''.join(fault), []).append(fault_id)
        fault_id += 1

    print "dict_by_fault_full:"
    print " ", num_bits, "bits total"
    print_histogram(signatures, num_faults)

def eval_pass_fail(dict_by_fault_pass_fail):
    signatures = {}
    fault_id = 0
    num_faults = len(dict_by_fault_pass_fail)
    num_tests = len(dict_by_fault_pass_fail[0])
    num_bits = num_faults * num_tests
    num_ones = 0
    for fault in dict_by_fault_pass_fail:
        signatures.setdefault(reduce(operator.concat, map(str, fault)), []).append(fault_id)
        num_ones += sum(map(int, fault))
        fault_id += 1

    print "dict_by_fault_pass_fail:"
    print " ", num_bits, "bits total"
    print_histogram(signatures, num_faults)
    print "  #P/#F: %8f" % ((1.0 * num_ones) / num_bits)

def eval_selected_test_pass_fail(selected_tests_pass_fail, dict_by_fault_pass_fail):
    fault_dict = []
    for fault in dict_by_fault_pass_fail:
        this_line = [fault[column_id] for column_id in selected_tests_pass_fail]
        fault_dict.append(this_line)
    eval_pass_fail(fault_dict)
    
def eval_compact(dict_by_fault_compact):
    signatures = {}
    fault_id = 0
    num_bits = len(dict_by_fault_compact) * len(dict_by_fault_compact[0])
    for fault in dict_by_fault_compact:
        signatures.setdefault(reduce(operator.concat, map(str, fault)), []).append(fault_id)
        fault_id += 1

    print "dict_by_fault_compact:"
    print " ", num_bits, "bits total"
    print_histogram(signatures, len(dict_by_fault_compact))

def count_pairs(n):
    """ Counts the number of pairs between N items. It's related to the binomial theorem somehow, whatever. """
    return (n * (n - 1)) / 2

def print_histogram(data, num_faults):
    # Updated to properly compute the diagnostic resolution as the ratio of distinguished to total fault pairs
    histogram = {}
    total_fp = count_pairs(num_faults)
    undistinguished_fp = 0
    for sig in data:
        size = len(data[sig])
        histogram[size] = histogram.setdefault(size, 0) + 1
    print "  Size       Count"
    for i in sorted(histogram):
        print "%6d  %10d" % (i, histogram[i])
        undistinguished_fp += histogram[i] * count_pairs(i) # yes, this even works for n=1
    dr = (1.0 * (total_fp - undistinguished_fp)) / total_fp
    print "  total_fp:", total_fp, "undistinguished_fp:", undistinguished_fp
    print "  Diagnostic resolution: %0.8f" % dr

# ------------------------------------------------------------------------------
# Functions to parse the various types of fault dictionary
def parse_dict_full(filename):
    dict_by_fault_full = []
    for line in file(filename):
        dict_by_fault_full.append(line.strip().split())
    return dict_by_fault_full

# ------------------------------------------------------------------------------
# Functions to create the various types of fault dictionary

def create_pass_fail(dict_by_fault_full, tests):
    """ Creates a pass-fail dictionary from a full response dictionary. """
    fault_id = 0
    dict_by_fault_pass_fail = []
    for fault in dict_by_fault_full:
        this_fault = []
        test_id = 0
        for test in fault:
            #print test, tests[test_id][1]
            this_fault.append("0" if (test == tests[test_id][1]) else "1")
            test_id += 1
        #print this_fault
        dict_by_fault_pass_fail.append(this_fault)
        fault_id += 1
    return dict_by_fault_pass_fail

def create_tfx_pass_fail(dict_by_fault_full):
    """ Creates a regular 0/1 pass/fail dictionary from a tfx full response dictionary. """
    dict_by_fault_pass_fail = []
    for fault in dict_by_fault_full:
        this_fault = []
        for test in fault:
            this_fault.append("1" if 'X' in test else "0")
        dict_by_fault_pass_fail.append(this_fault)
    return dict_by_fault_pass_fail

def create_xored_pass_fail(dict_by_fault_pass_fail):
    """ Creates an XORed pass-fail dictionary as detailed in Arslan02. """
    dict_by_fault_xored_pass_fail = []
    for fault in dict_by_fault_pass_fail:
        this_fault = []
        prior_value = 0
        for test in fault:
            this_value = int(test) ^ prior_value
            this_fault.append(str(this_value))
            prior_value = this_value
        dict_by_fault_xored_pass_fail.append(this_fault)

    return dict_by_fault_xored_pass_fail

def create_d_table_by_fault(dict_by_fault_pass_fail):
    """ Creates the big huge nasty distinguishability table for the provided pass-fail dictionary. Also works with XORed pass fail dictionaries. """
    d_table_by_fault = []

    int_pf = []
    for fault in dict_by_fault_pass_fail:
        int_pf.append(map(int, fault))

    num_faults = len(dict_by_fault_pass_fail)
    num_tests = len(dict_by_fault_pass_fail[0])
    for i in range(num_faults):
        print "%d / %d = %f" % (i, num_faults, (1.0 * i) / num_faults)
        for j in range(i + 1, num_faults):
            #print "fault pair is (%d, %d)" % (i, j)
            d_row = [int_pf[i][x] ^ int_pf[j][x] for x in range(num_tests)]
            d_table_by_fault.append(map(str, d_row))

    return d_table_by_fault

def do_greedy_set_cover(d_table_by_fault):
    """ Performs a greedy set cover on the provided d_table. Returns a list of column IDs that best cover the rows. If the rows are not coverable, then the returned list covers as many rows as possible. """

    num_fault_pairs = len(d_table_by_fault)
    num_tests = len(d_table_by_fault[0])

    remaining_fault_pair_ids = set(range(num_fault_pairs))
    remaining_column_ids = set(range(num_tests))
    columns = []
    while len(remaining_fault_pair_ids) > 0:
        print "--------------------------------------------------------------------------------"
        print "There are %d fault pairs remaining" % len(remaining_fault_pair_ids)
        best_dstg_fp_ids = set() # best distinguished fault pair ids list
        best_column_id = None
        for column_id in remaining_column_ids:
            #print "  Checking column ID:", column_id
            this_dstg_fp_ids = set()
            for fp_id in remaining_fault_pair_ids:
                if d_table_by_fault[fp_id][column_id] == "1":
                    this_dstg_fp_ids.add(fp_id)
            #originaleprint "    this dstg fp ids:", len(this_dstg_fp_ids)
            if len(this_dstg_fp_ids) > len(best_dstg_fp_ids):
                best_dstg_fp_ids = this_dstg_fp_ids
                best_column_id = column_id

        if len(best_dstg_fp_ids) == 0:
            # couldn't improve any further, can't cover all the rows
            print "Cannot improve any further, this d_table is not coverable."
            print "Returning with %d / %d columns selected..." % (len(columns), num_tests)
            break # out of this loop, and return the list of column IDs

        #print "  End of iteration:"
        print "    best dstg fp ids:", len(best_dstg_fp_ids)
        print "    best column ID:", best_column_id

        # remove now distinguished fault pair ids from the list
        remaining_fault_pair_ids -= best_dstg_fp_ids
        remaining_column_ids.remove(best_column_id)
        columns.append(best_column_id)
    return columns

def find_ef(dict_by_fault_pass_fail, test_set_ids):
    """ Computes the edge factor as described in hong07. Returns a value that can be used to compute the number of remaining edges. """
    hash_table = {}

    # compute the SID of each fault under this test set, look up the counter in the hash table, and inrement it
    for fault in dict_by_fault_pass_fail:
        sid = "".join(fault[x] for x in test_set_ids)
        hash_table[sid] = hash_table.get(sid, 0) + 1 # increment the counter for this signature

    # 2. find the cardinality of each fault equivalence set, and use it to compute EF
    ef = 0
    for sid in hash_table:
        ef += hash_table[sid]**2

    return ef

def do_greedy_set_cover_enhanced(dict_by_fault_pass_fail):
    """ Performs a greedy set cover to select the best tests to keep, without generating the entire d_table, as described in hong07. Returns a list of column IDs. """
    num_faults = len(dict_by_fault_pass_fail)
    num_tests = len(dict_by_fault_pass_fail[0])
    remaining_column_ids = set(range(num_tests))
    columns = []
    N = math.ceil(math.log(num_faults, 2))
    print "N:", N
    while True:
        print "--------------------------------------------------------------------------------"
        print "Columns:", columns
        best_ef = None
        best_column_id = None
        for column_id in remaining_column_ids:
            #print "  Checking column ID:", column_id
            ts = columns[:]
            ts.append(column_id)
            ef = find_ef(dict_by_fault_pass_fail, ts)
            #print "    EF:", ef
            if not best_ef or ef < best_ef:
                best_ef = ef
                best_column_id = column_id

        if not best_ef:
            # couldn't improve any further, can't cover all the rows
            print "Cannot improve any further, this dictionary is not completely coverable."
            break # out of this loop, and return the list of column IDs

        #print "  End of iteration:"
        print "    best EF:", best_ef
        print "    best column ID:", best_column_id

        # remove now distinguished fault pair ids from the list
        remaining_column_ids.remove(best_column_id)
        columns.append(best_column_id)

        if best_ef <= num_faults or len(columns) >= N: #(N = given upper bound on the number of selected vectors)
            break # out of this while loop, sine we are finished

    print "Returning with %d / %d columns selected..." % (len(columns), num_tests)
    return columns

if __name__ == "__main__":

    if len(sys.argv) < 2:
        print "Error: You must specify the basename."
        print "Usage: %s basename" % sys.argv[0]
        sys.exit(1)
    basename = sys.argv[1] + "/" + sys.argv[1]

    faults = parse_tmax_faults(basename + ".faults")
    num_faults = len(faults)
    print "Parsed %d faults" % num_faults
    #print "Faults:", faults

    tests, po_list = parse_tmax_tests(basename + ".tests")
    num_tests = len(tests)
    num_po = len(po_list)
    print "Parsed %d test patterns" % num_tests
    print "There are %d primary outputs" % num_po
    #print "Tests:", tests
    #print "Primary Outputs:", po_list

    fault_data = []
    for test_id in range(num_tests):
        fault_data.append([x for x in tests[test_id][1]])
    #print "fault_data: (%d, %d)" % (len(fault_data), len(fault_data[0]))
    #print fault_data
    #print "Expected output:\n   ", [''.join(test) for test in fault_data]

    print ""

    print "generating dict by fault full"
    dict_by_fault_full = []
    for f, sa in faults:
        filename = sys.argv[1] + "/sim/sim.{0}.{1}".format(pin_to_file_name(f), sa)
        #print filename
        dict_by_fault_full.append(parse_tmax_sim_result(filename, po_list, fault_data))
        #print "Fault response:", f, sa, "\n   ", dict_by_fault_full[-1]

    write_full(basename + ".dict_by_fault_full", dict_by_fault_full)
    eval_full(dict_by_fault_full)

    print ""
    sys.exit(0)

    # pass fail
    print "genrating dict by fault pass fail"
    dict_by_fault_pass_fail = create_pass_fail(dict_by_fault_full, tests)
    #for fault in dict_by_fault_pass_fail:
        #print "".join(fault)
    write_pass_fail(basename + ".dict_by_fault_pass_fail", dict_by_fault_pass_fail)
    eval_pass_fail(dict_by_fault_pass_fail)

    print ""

    # XORed pass-fail
    print "generating XORed pass fail dictionary"
    dict_by_fault_xored_pass_fail = create_xored_pass_fail(dict_by_fault_pass_fail)
    #for fault in dict_by_fault_xored_pass_fail:
        #print "".join(fault)
    write_xored_pass_fail(basename + ".dict_by_fault_xored_pass_fail", dict_by_fault_xored_pass_fail)
    eval_pass_fail(dict_by_fault_xored_pass_fail)

    print ""

    use_slow_d_table_method = False
    if use_slow_d_table_method:
        # distinguishability table for original pass fail dictionary
        print "Generating distinguishability table for original pass fail dictionary"
        d_table_by_fault_pass_fail = create_d_table_by_fault(dict_by_fault_pass_fail)
        #for fault in d_table_by_fault_pass_fail:
            #print ",".join(fault)

        print ""

        # distinguishability table for xored pass fail dictionary
        print "Generating distinguishability table for xored pass fail dictionary"
        d_table_by_fault_xored_pass_fail = create_d_table_by_fault(dict_by_fault_xored_pass_fail)
        #for fault in d_table_by_fault_xored_pass_fail:
            #print fault

        print ""
        # do greedy set covering on distinguishability table with original pass fail dictionary
        print "Doing greedy set cover on d-table for original pass-fail dictionary"
        d_table_columns_pass_fail = do_greedy_set_cover(d_table_by_fault_pass_fail)

        print ""
        # do greedy set covering on distinguishability table with XORed pass fail dictionary
        print "Doing greedy set cover on d-table for XORed pass-fail dictionary"
        d_table_columns_xored_pass_fail = do_greedy_set_cover(d_table_by_fault_xored_pass_fail)

        print len(d_table_columns_pass_fail)
        print len(d_table_columns_xored_pass_fail)

    else:
        # use new faster d_table method

        #print "Performing enhanced greedy test selection without d_table generation for pass fail"
        #selected_tests_pass_fail = do_greedy_set_cover_enhanced(dict_by_fault_pass_fail)
        #print selected_tests_pass_fail
        #eval_selected_test_pass_fail(selected_tests_pass_fail, dict_by_fault_pass_fail)

        print ""
        print "Performing enhanced greedy test selection without d_table generation for XORed pass fail"
        selected_tests_xored_pass_fail = do_greedy_set_cover_enhanced(dict_by_fault_xored_pass_fail)
        print selected_tests_xored_pass_fail
        eval_selected_test_pass_fail(selected_tests_xored_pass_fail, dict_by_fault_xored_pass_fail)



